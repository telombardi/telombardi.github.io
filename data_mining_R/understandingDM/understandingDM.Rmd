---
title: 'Chapter 2: Understanding Data Mining'
output: 
    tufte::tufte_html:
      highlight: tango
---

#Understanding Data Mining

```{marginfigure}
Chapter Summary:
This chapter introduces some basic concepts of data mining with simple
examples in R.
```

_Data Mining_ is a computational process for discovering meaningful patterns
in large sets of data.[^1]

[^1]: https://en.wikipedia.org/wiki/Data_mining

Data Mining is used in almost every discipline to learn from the 
rapidly expanding troves of data generated by modern computer 
technology.

#Data Mining Process

The data mining community has produced a number of standards to help
people implement the data mining process. In this class, we will 
sometimes refer to _CRISP-DM_, Cross Industry Standard Process for Data Mining. [^2]

[^2]: https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining

The CRISP-DM method includes the following phases:

##Project Understanding
  * In this phase, we try to understand the problem from the point of 
  view of the business or research objectives. 
  * These real-world objectives are translated into specific data mining
  objectives.

##Data Understanding
  This phase can include:
  
  * data collection;
  * preliminary data analysis; 
  * data quality review.

##Data Preparation
  Data preparation takes the data in its initial form and 
  transforms it into its final form for analysis. This may include 
  many steps such as:
  
  * Outlier analysis
  * Handling missing values
  * Separating data into training and testing sets

##Modeling
  * Data mining models are used to "mine" the data set for information
  relevant to the problem.
  * _Descriptive models_ construct accurate portrayals of some 
aspect of the real world with data.
  * _Exploratory models_ help researchers to discover insights in their data.
  * _Explanatory models_ aim to identify causal relationships in data.
  * _Predictive models_ forecast real-world outcomes based on data.

##Evaluation
  * The results of the modeling phase are put into perspective and 
  tested where possible. 
  * Do the results meet the needs of the project?

##Deployment
  * Implement the model for business or research purposes.
  * Document the knowledge generated from this process.

#Types of Modeling in Data Mining
##Descriptive Modeling

Descriptive modeling attempts to provide an accurate portrayal of some 
aspect of the real world with data.

_Problem Understanding_

Sometimes, we want to understand how to compare things. We often do this 
in sports. People like to argue about their favorite players based on their
statistics. Suppose I am a Rod Carew fan and I wanted to understand 
Carew's career statistics. In other words, I want to answer the question:
how good of a batter was Rod Carew?

We might use descriptive modeling to help us answer this question.

To make the example straight forward, let's assume that a career batting
average is a good way to summarize a batter's career (even though it isn't).

So we can formalize our problem with a more specific question based on our 
data model.

How does Rod Carew's batting average compare to that of other players?

It's very important to recognize that we've already made a crucial 
modeling decision. We've assumed that batting averages provide a decent 
basis for comparing the performance of batters. 

_Data Understanding_

In the data understanding phase, we'll want to make sure that we understand 
batting averages (our data model). We'll also want to make sure that 
we can get the data we need. Luckily, we can get the data from a handy 
reference site: http://www.baseball-reference.com/leaders/batting_avg_career.shtml

_Data Preparation_

Unfortunately, we can't use the data as it is published on the website.
We will need to cleanse the data to make sure that we can use it properly.

We will need to install packages that can help us cleanse our data.

```
install.packages('rvest')
install.packages('stringr')
install.packages('tidyr')
```
Then we need to load those packages to make them available to our 
program.

```{r}
library(rvest)
library(stringr)
library(tidyr)
library(xml2)
```

Now we are reading to cleanse our data.

* We read the html page with the data we want.

* We extract the HTML tables from the webpage.

* We extract the first HTML table. 

```{r}
batters <- "http://www.baseball-reference.com/leaders/batting_avg_career.shtml"
webpage <- read_html(batters)
sb_table <- html_nodes(webpage, 'table')
sb <- html_table(sb_table)[[1]]
head(sb)
```

* We only need columns 2 and 3 for our analysis.

* We want to be sure that the batting averages are treating as numeric data types.

```{r}
bat <- sb[,2:3]
bat[,2] <- as.numeric(sb[,3])
```

* We have to remove records with batting averages that do not represent numbers.

```{r}
bat[is.na(bat[,2]),]
bat <- bat[!is.na(bat[,2]),]
```

* Finally we have the data in a format we can process.

```{r}
summary(bat)
str(bat)
```

_Modeling_

We will model a single variable: batting average. This should help us
put Rod Carew's career batting into perspective.

```{r fig.margin=TRUE, fig.cap="Histogram of Batting Averages"}
hist(bat[,2])
```

```{r fig.margin=TRUE, fig.cap="Density Plot of Batting Averages"}
plot(density(bat[,2]))
abline(v = .3278, col="red")
```

_Evaluation_

Do our results shed light on our original problem?
Rod Carew's batting average does look elite even in this sample.
What's more, Carew might be in a very small group of 
extremely elite batters.

Are there problems with our approach?
We are comparing Carew's numbers to other elite batters. In other words, 
this isn't a random sample of batters: it's biased toward good batters.
Given our question, this is not really a problem, but it's always a 
good idea to consider the bias in our samples.

What else can we learn from these data?
In the distribution, we see both a big bump of good batters and a small 
bump of great batters. We might like to know if Carew is closer to the 
big group or small group. We'll examine this question in our example 
of exploratory modeling.

_Deployment_

In this case, deployment might mean simply reporting our results to 
peers. 

##Exploratory Modeling

Exploratory models help researchers to discover insights in their data.

_Problem Understanding_

We still want to put Carew's batting average in perspective. When 
we performed descriptive modeling, we identified two different 
bumps in the distribution of the batters: good and great.

We want to use that observation to help us see if Carew's metrics 
are more like the good or the great batters.

We can formalize this by performing cluster analysis which is a common 
approach to exploratory modeling.

_Data Understanding_

Since we performed our data analysis already, we already understand these 
data pretty well. 

_Data Preparation_

We've also already formatted our data in a pretty good state. We will need to 
perform a few steps to perform clustering analysis.

First, we need to create a distance matrix which estimates the distance
between every batter and every other batter based on their batting 
averages.

```{r}
d <- dist(bat[,2])
head(d)
```

_Modeling_

The distance matrix serves as input to the hierarchical clustering
algorithm. Since we know from our descriptive model, we expect 
two clusters and we show each cluster in a red box.

```{r fig.margin=TRUE, fig.cap="Dendrogram of Hierarchical Cluster of Batters"}
h <- hclust(d)
plot(h)
rect.hclust(h, k = 2, border = "red")
```

_Evaluation_

It looks like we have good reason to believe that Rod Carew 
should be considered among the greatest of batters.
He easily falls into the cluster of great batters.
We might to try additional clustering techniques or validate our 
choice of two clusters in these data.

```{r}
ct <- cutree(h, 2)
table(ct)
```

We can see that the first 188 batters are in the elite group which 
includes Rod Carew.

_Deployment_

Again, deployment in this case might simply be using our knowledge and 
visualizations to help document our case.

##Explanatory Modeling

Explanatory models aim to identify causal relationships in data.

_Problem Understanding_

We want to understand how smoking affects our health.
In other words, we want to explain the relationship between 
smoking cigarettes and lifespan.

We can formalize this by comparing people's smoking habits with their 
longevity. In such cases, researchers often use linear regression.

_Data Understanding_

Consider the following dataset. Source: http://www.real-statistics.com/correlation/one-sample-hypothesis-testing-correlation/

The dataset collects the smoking behavior and longevity of 15 males 50 or above.

"Cigarettes" measures the average number of cigarettes smoked per day.

"Longevity" measures each participant's age in years at the time of his death.

_Data Preparation_

Since the data were collected as part of an experiment, the data are 
already fairly well prepared. We can read them and review them for 
good measure.

```{r}
data <- read.csv("cigarettes.csv")
summary(data)
```

_Modeling_

We will use a linear regression model to identify how cigarettes 
affect health as measured by longevity.

We start by looking at the correlation between these two variables.

```{r}
cor(data)
cor.test(data$cigarettes,data$longevity)
```

We can see that there is a negative relationship between smoking and 
longevity. It can be helpful to plot these variables to confirm 
that their relationship represents a linear relationship.

```{r fig.margin=TRUE, fig.cap="Density Plot of Batting Averages"}
plot(data$longevity,data$cigarettes)
abline(lm(data$cigarettes ~ data$longevity), col="red")
```

The fitted line does more or less represent the center of the data 
in the scatter plot. So we have decent reason to believe that there is 
a linear relationship between the two variables.

Now we can create a linear regression formula to explain the 
relationship between these variables more formally.

```{r}
lmfit <- lm(longevity ~ cigarettes, data=data)
lmfit
```

_Evaluation_

At this point, we want to make sure that the regression formula is a reasonable 
explanatory model.

```{r}
summary(lmfit)
```

In order to evaluate this model, we want to know:

1) How likely is this model the result of random variation?

The p-value (probability value) associated with the F-statistic
tells us that the model is unlikely to be the result of random 
variation. In other words, we have a statistically significant fit.

2) How much of the variation in the data does our model explain?

The adjusted R-squared value tells us that our linear model explains 
just a bit less than half of the variation found in the data.

Although these are reasonable results, we will want to consider the limits 
of our model including:

1) Our model is way too simple. Clearly other things contribute to health
beside smoking. We probably want to consider other variables that will 
help us understand this problem better.

2) Our model is biased because it only samples males over 50. We almost 
certainly want to include gender in our model as well.

_Deployment_

As in previous examples, we will want to document our work thoroughly.

##Predictive Modeling

Predictive models forecast real-world outcomes based on data.

_Problem Understanding_

Now we would like to predict how long our 
55 year old friend will live who smokes 25 cigarettes a day on average.

_Data Understanding_

We have already spent some time reviewing the data when we created our 
explanatory model. We can move forward at this point.

_Data Preparation_

Since predictive models often require training sets and testing sets, 
the data preparation phase must include the creation of these data sets.

We will use the data frame from our explanatory model as our training set.
Then we will create our testing set with the data specific to our friend.

```{r}
newdata <- data.frame(cigarettes=25,longevity=0)
```

_Modeling_

We now use our model to predict our friend's longevity based on his 
smoking behavior.

```{r}
predict(lmfit, newdata=newdata) 
```

_Evaluation_

Since we can't immediately evaluate our prediction, we'll need to 
be creative when trying to assess our model. Data mining is a 
repetitive process. We will need to refine this model on 
a repeated basis to respond to new trends and data.

_Deployment_

We may want to deploy our formula to a website to help people think about 
the health consequences of their behavior. 

#Summary

In this chapter, we learned about the data mining process and four 
different types of models we will use in our data mining projects.

#References

R Core Team (2016). R: A language and environment for statistical
  computing. R Foundation for Statistical Computing, Vienna, Austria. URL
  https://www.R-project.org/.
  
#Session Information

```{r}
sessionInfo()
```